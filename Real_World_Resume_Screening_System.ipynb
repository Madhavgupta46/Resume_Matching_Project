{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing data**\n",
        "These resumes are made by chatgpt so i get a data of 20 samples which is noisy too\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XC0VSIEhpld3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resumes = [\n",
        "\n",
        "\"\"\"\n",
        "RAHUL SHARMA\n",
        "Email: rahul.ds@gmail.com | Phone: 98xxxxxxx\n",
        "\n",
        "SKILLS:\n",
        "Python, Machine Learning, Pandas, NumPy , Scikit Learn\n",
        "NLP / Text Mining / Data Analysis\n",
        "\n",
        "EDUCATION:\n",
        "B.Sc Data Science (2022â€“2025)\n",
        "\n",
        "PROJECTS:\n",
        "â€¢ Sentiment Analysis using NLP!!!\n",
        "â€¢ Resume Screening System\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "AMIT KUMAR\n",
        "Contact: amitk@email.com\n",
        "\n",
        "Skills:\n",
        "Java | Spring Boot | SQL | REST APIs\n",
        "\n",
        "Experience:\n",
        "Backend Developer Intern\n",
        "\n",
        "Education:\n",
        "BTech Computer Science\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "NEHA SINGH\n",
        "\n",
        "Skills :- Python, NLP, Deep Learning, TensorFlow, Keras\n",
        "Experience: Chatbots, Resume Parser, ML models\n",
        "\n",
        "Education : MSc Artificial Intelligence\n",
        "Github: github.com/neha-ai\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "PROFILE:\n",
        "C++ Developer\n",
        "\n",
        "Skills:\n",
        "C++, DSA, Algorithms, Competitive Programming!!!!!\n",
        "\n",
        "Education:\n",
        "BTech IT\n",
        "\n",
        "Achievements:\n",
        "Codeforces, CodeChef\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "Name: Kunal Verma\n",
        "\n",
        "Skills:\n",
        "Python | Pandas | NumPy | Power BI | Excel\n",
        "\n",
        "Experience:\n",
        "Data cleaning, dashboards, reporting\n",
        "\n",
        "Education:\n",
        "BCom\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "SANJAY MEHTA\n",
        "\n",
        "SKILLS:\n",
        "Python, Machine Learning, Feature Engineering\n",
        "Libraries: scikit-learn, matplotlib\n",
        "\n",
        "Education:\n",
        "BSc Statistics\n",
        "\n",
        "Projects:\n",
        "Predictive modeling\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "RITU JAIN\n",
        "Email: ritu_jain@gmail.com\n",
        "\n",
        "Skills:\n",
        "SQL, Excel, Power BI\n",
        "Data Visualization, Reporting\n",
        "\n",
        "Education:\n",
        "MBA (Analytics)\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "ARJUN SINGH\n",
        "\n",
        "Skills:\n",
        "Python, Flask, Streamlit, ML Deployment\n",
        "Experience:\n",
        "Deployed ML apps on cloud\n",
        "\n",
        "Education:\n",
        "BTech CSE\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "MOHIT AGRAWAL\n",
        "\n",
        "Skills:\n",
        "R, Statistics, Machine Learning\n",
        "Experience:\n",
        "Regression, classification models\n",
        "\n",
        "Education:\n",
        "MSc Statistics\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "ANANYA DAS\n",
        "\n",
        "Skills:\n",
        "Python, NLP, Sentiment Analysis, Text Mining\n",
        "Experience:\n",
        "Worked on social media data\n",
        "\n",
        "Education:\n",
        "MSc Data Science\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "PROFILE SUMMARY:\n",
        "Frontend Developer\n",
        "\n",
        "Skills:\n",
        "HTML, CSS, JavaScript, React\n",
        "\n",
        "Projects:\n",
        "Web UI development\n",
        "\n",
        "Education:\n",
        "BCA\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "NAME: ROHIT PATEL\n",
        "\n",
        "Skills:\n",
        "Python, Data Analysis, Pandas, NumPy\n",
        "Experience:\n",
        "Exploratory Data Analysis\n",
        "\n",
        "Education:\n",
        "BSc Mathematics\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "POOJA SHARMA\n",
        "\n",
        "Skills:\n",
        "Machine Learning, Python, scikit-learn\n",
        "Experience:\n",
        "ML mini projects\n",
        "\n",
        "Education:\n",
        "BTech AI\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "AKASH GUPTA\n",
        "\n",
        "Skills:\n",
        "AWS, Docker, Linux, CI/CD\n",
        "Experience:\n",
        "Cloud infrastructure\n",
        "\n",
        "Education:\n",
        "BTech IT\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "SNEHA KAPOOR\n",
        "\n",
        "Skills:\n",
        "Python, NLP, Transformers, HuggingFace\n",
        "Experience:\n",
        "Text classification projects\n",
        "\n",
        "Education:\n",
        "MSc AI\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "PROFILE:\n",
        "Business Analyst\n",
        "\n",
        "Skills:\n",
        "Excel, SQL, PowerPoint\n",
        "Experience:\n",
        "Requirement gathering\n",
        "\n",
        "Education:\n",
        "MBA\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "NAME: VIKAS MALIK\n",
        "\n",
        "Skills:\n",
        "Python, Data Science, Visualization\n",
        "Libraries:\n",
        "Seaborn, Matplotlib\n",
        "\n",
        "Education:\n",
        "BSc Data Analytics\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "SHUBHAM YADAV\n",
        "\n",
        "Skills:\n",
        "Java, DSA, OOPs\n",
        "Experience:\n",
        "Problem solving\n",
        "\n",
        "Education:\n",
        "BTech CSE\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "SONALI KHAN\n",
        "\n",
        "Skills:\n",
        "Python, NLP, Resume Parsing\n",
        "Experience:\n",
        "Text preprocessing\n",
        "\n",
        "Education:\n",
        "MSc Computer Science\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"\n",
        "PROFILE SUMMARY:\n",
        "ML Engineer\n",
        "\n",
        "Skills:\n",
        "Python, Machine Learning, Deep Learning\n",
        "Libraries:\n",
        "TensorFlow, PyTorch\n",
        "\n",
        "Education:\n",
        "MTech AI\n",
        "\"\"\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "c0Pd0MaSpRJr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"\"\"\n",
        "HIRING!!! Data Science Intern ðŸš€\n",
        "\n",
        "Requirements:\n",
        "- Strong PYTHON skills\n",
        "- Machine learning basics\n",
        "- Pandas, NumPy\n",
        "- NLP knowledge is a PLUS\n",
        "- scikit learn experience\n",
        "\n",
        "Send resume ASAP!!!\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "kKhf4L8VpUv6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total resumes:\", len(resumes))\n",
        "print(\"\\nSample resume:\\n\")\n",
        "print(resumes[0])\n",
        "\n",
        "print(\"\\nJob description:\\n\")\n",
        "print(job_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA53CXBJpVyZ",
        "outputId": "dcb68daf-a287-4d57-c4d9-101076781e67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total resumes: 20\n",
            "\n",
            "Sample resume:\n",
            "\n",
            "\n",
            "RAHUL SHARMA\n",
            "Email: rahul.ds@gmail.com | Phone: 98xxxxxxx\n",
            "\n",
            "SKILLS:\n",
            "Python, Machine Learning, Pandas, NumPy , Scikit Learn\n",
            "NLP / Text Mining / Data Analysis\n",
            "\n",
            "EDUCATION:\n",
            "B.Sc Data Science (2022â€“2025)\n",
            "\n",
            "PROJECTS:\n",
            "â€¢ Sentiment Analysis using NLP!!!\n",
            "â€¢ Resume Screening System\n",
            "\n",
            "\n",
            "Job description:\n",
            "\n",
            "\n",
            "HIRING!!! Data Science Intern ðŸš€\n",
            "\n",
            "Requirements:\n",
            "- Strong PYTHON skills\n",
            "- Machine learning basics\n",
            "- Pandas, NumPy\n",
            "- NLP knowledge is a PLUS\n",
            "- scikit learn experience\n",
            "\n",
            "Send resume ASAP!!!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pre-processing**"
      ],
      "metadata": {
        "id": "jfus3WvAq2Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download once in Colab\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    # 1. lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. remove emails\n",
        "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
        "\n",
        "    # 3. remove numbers\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "    # 4. remove punctuation & symbols\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "\n",
        "    # 5. tokenize\n",
        "    tokens = text.split()\n",
        "\n",
        "    # 6. remove stopwords + lemmatize\n",
        "    tokens = [\n",
        "        lemmatizer.lemmatize(word)\n",
        "        for word in tokens\n",
        "        if word not in stop_words\n",
        "    ]\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgY-OGcRpWxg",
        "outputId": "8ab12b2c-0734-4be5-c8ea-66fde643e0bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_resumes = [clean_text(resume) for resume in resumes]\n",
        "clean_job = clean_text(job_description)\n",
        "\n",
        "print(\"CLEANED RESUME SAMPLE:\\n\")\n",
        "print(clean_resumes[0])\n",
        "\n",
        "print(\"\\nCLEANED JOB DESCRIPTION:\\n\")\n",
        "print(clean_job)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpha6x87q_A8",
        "outputId": "d4990a3e-260b-4a61-a59e-541d1b32994b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLEANED RESUME SAMPLE:\n",
            "\n",
            "rahul sharma email phone xxxxxxx skill python machine learning panda numpy scikit learn nlp text mining data analysis education b sc data science project sentiment analysis using nlp resume screening system\n",
            "\n",
            "CLEANED JOB DESCRIPTION:\n",
            "\n",
            "hiring data science intern requirement strong python skill machine learning basic panda numpy nlp knowledge plus scikit learn experience send resume asap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TF-IDF VECTORIZATION**"
      ],
      "metadata": {
        "id": "6dUcNvJcujKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "pB-ZZG1Wua8Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit on resumes\n",
        "tfidf_resumes = vectorizer.fit_transform(clean_resumes)\n",
        "\n",
        "print(\"TF-IDF matrix shape:\", tfidf_resumes.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia0t08bKuqER",
        "outputId": "7b20cd9f-c1d9-449b-f393-b7e66dbf2ffc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF matrix shape: (20, 155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_job = vectorizer.transform([clean_job])\n",
        "print(\"Job vector shape:\", tfidf_job.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DjvnMQpusEK",
        "outputId": "796b8764-9b49-4889-9e12-db4d126ac84b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job vector shape: (1, 155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Compute similarity (cosine similarity)**"
      ],
      "metadata": {
        "id": "UEga-miQv9QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_scores = cosine_similarity(tfidf_job, tfidf_resumes)\n",
        "\n",
        "print(\"Similarity scores:\\n\", similarity_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8ej1JgBvdrQ",
        "outputId": "5a7452ff-7fb1-4b66-d66b-3bbaa4425fc8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity scores:\n",
            " [[0.49381428 0.17107743 0.15294833 0.01097312 0.23098605 0.25033498\n",
            "  0.05688509 0.04899696 0.13075354 0.23085261 0.00940947 0.26926479\n",
            "  0.34017763 0.03085201 0.11779882 0.16157577 0.17628969 0.03351938\n",
            "  0.25580748 0.17337406]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Rank resumes**\n"
      ],
      "metadata": {
        "id": "h4B4gatGwkvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Flatten to 1D array\n",
        "scores = similarity_scores.flatten()\n",
        "\n",
        "# Rank resumes\n",
        "ranked_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "print(\"Resume ranking (best â†’ worst):\")\n",
        "for idx in ranked_indices:\n",
        "    print(f\"Resume {idx+1} : Score = {scores[idx]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STDz93qkv-Bs",
        "outputId": "f5222bca-9d98-4723-ad40-2e5b0decfc9a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume ranking (best â†’ worst):\n",
            "Resume 1 : Score = 0.4938\n",
            "Resume 13 : Score = 0.3402\n",
            "Resume 12 : Score = 0.2693\n",
            "Resume 19 : Score = 0.2558\n",
            "Resume 6 : Score = 0.2503\n",
            "Resume 5 : Score = 0.2310\n",
            "Resume 10 : Score = 0.2309\n",
            "Resume 17 : Score = 0.1763\n",
            "Resume 20 : Score = 0.1734\n",
            "Resume 2 : Score = 0.1711\n",
            "Resume 16 : Score = 0.1616\n",
            "Resume 3 : Score = 0.1529\n",
            "Resume 9 : Score = 0.1308\n",
            "Resume 15 : Score = 0.1178\n",
            "Resume 7 : Score = 0.0569\n",
            "Resume 8 : Score = 0.0490\n",
            "Resume 18 : Score = 0.0335\n",
            "Resume 14 : Score = 0.0309\n",
            "Resume 4 : Score = 0.0110\n",
            "Resume 11 : Score = 0.0094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Saving the model & vectorizer**"
      ],
      "metadata": {
        "id": "uAOynEhLxEd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "# Save cleaned resumes (optional, if you want preprocessed data)\n",
        "with open(\"clean_resumes.pkl\", \"wb\") as f:\n",
        "    pickle.dump(clean_resumes, f)\n"
      ],
      "metadata": {
        "id": "qrMukt9UwFOl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tqo_dUR9xWdO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}